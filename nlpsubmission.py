# -*- coding: utf-8 -*-
"""NLPSubmission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13ANW4BnXfAyOKKlTOVK1jJB9apnF8C7Z
"""

import pandas as pd

df = pd.read_csv('train.csv')

df

df.tail(10)

category = pd.get_dummies(df.author)

df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='author')
df_baru

text = df_baru['text'].values

label = df_baru[['EAP', 'HPL', 'MWS']].values

from sklearn.model_selection import train_test_split

text_latih, text_test, label_latih, label_test = train_test_split(text, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x')

tokenizer.fit_on_texts(text_latih)
tokenizer.fit_on_texts(text_test)

sekuens_latih = tokenizer.texts_to_sequences(text_latih)
sekuens_test = tokenizer.texts_to_sequences(text_test)

padded_latih = pad_sequences(sekuens_latih, padding='post', maxlen=20, truncating='post') 
padded_test = pad_sequences(sekuens_test, padding='post', maxlen=20, truncating='post')

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=32),
    tf.keras.layers.LSTM(128),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(3, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if (logs.get('accuracy')> 0.9) and (logs.get('val_accuracy')> 0.75):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True

callbacks = myCallback()

num_epochs = 100
history = model.fit(padded_latih, label_latih, batch_size=256, epochs=num_epochs, 
                    validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

# Evaluasi Hasil

# Accuracy dan validation
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

# Loss dan validation
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

# Accuracy & validation plot
plt.plot(epochs, acc, label="accuracy")
plt.plot(epochs, val_acc, label="validation accuracy")
plt.title('Akurasi Training dan Validation')
plt.legend(loc="upper left")

# Loss & validation plot
plt.plot(epochs, loss, label="loss")
plt.plot(epochs, val_loss, label="validation loss")
plt.legend(loc="upper left")
plt.title('Loss training dan validation')